{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rmotr](https://www.wingoo-solutions.fr/194/105-logo-asi.gif)\n",
    "<hr style=\"margin-bottom: 20px;\">\n",
    "\n",
    "# Rapport sur l'accidentalité en france\n",
    "#### Source: Ministère de l'intérieur sur data.gouv.fr\n",
    "<hr style=\"margin-bottom: 20px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: Importer et nettoyer les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture et jointu des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 958469 lignes importées à partir des fichiers de caracteristiques\n",
      "====== 958469 lignes importées à partir des fichiers de lieux\n",
      "====== 2142195 lignes importées à partir des fichiers de usagers\n",
      "====== Jointure des dataframe caracteristiques, lieux et usagers \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fichiers caracteristiques\n",
    "all_files_caracteristiques = glob.glob(r'C:\\DataSources\\caracteristiques' + \"/*.csv\") # Lister les fichiers contenus dans le path\n",
    "li_caracteristiques = [] # Initialiser la lister de lécture\n",
    "for filename in all_files_caracteristiques: # Boucler sur les fichiers en les lisant\n",
    "    df = pd.read_csv(filename, index_col=None, header=0, encoding = \"latin\") # Bien spécifier encoding = \"latin\"\n",
    "    li_caracteristiques.append(df) \n",
    "frame_caracteristiques = pd.concat(li_caracteristiques, axis=0, ignore_index=True) # Créer un dataframe à partir de la liste des fichiers lus\n",
    "print('====== {} lignes importées à partir des fichiers de caracteristiques'.format(frame_caracteristiques['Num_Acc'].count()))\n",
    "\n",
    "\n",
    "# Lecture lieux \n",
    "all_files_lieux = glob.glob(r'C:\\DataSources\\lieux' + \"/*.csv\")\n",
    "li_lieux = []\n",
    "for filename in all_files_lieux:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0, encoding = \"latin\", sep=',', low_memory=False)\n",
    "    li_lieux.append(df)\n",
    "frame_lieux = pd.concat(li_lieux, axis=0, ignore_index=True)\n",
    "print('====== {} lignes importées à partir des fichiers de lieux'.format(frame_lieux['Num_Acc'].count()))\n",
    "\n",
    "# Lecture usagers \n",
    "all_files_usagers = glob.glob(r'C:\\DataSources\\usagers' + \"/*.csv\")\n",
    "li_usagers = []\n",
    "for filename in all_files_usagers:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0, encoding = \"latin\", sep=',', low_memory=False)\n",
    "    li_usagers.append(df)\n",
    "frame_usagers = pd.concat(li_usagers, axis=0, ignore_index=True)\n",
    "print('====== {} lignes importées à partir des fichiers de usagers'.format(frame_usagers['Num_Acc'].count()))\n",
    "\n",
    "#### Jointure des accidents\n",
    "frame_accident = pd.merge(frame_caracteristiques, frame_lieux, on = 'Num_Acc')\n",
    "df_acc_usr = pd.merge(frame_accident, frame_usagers, on = 'Num_Acc')\n",
    "df_acc_usr['grav'] = df_acc_usr['grav'].map(lambda x: 1 if x == 2 else 0 )  # Accident morte = 1 autre accident = 0\n",
    "print(f'====== Jointure des dataframe caracteristiques, lieux et usagers \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mise en forme des dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2017-01-11 18:20:00\n",
      "1   2017-01-11 18:20:00\n",
      "2   2017-01-11 18:20:00\n",
      "3   2017-02-13 16:30:00\n",
      "4   2017-02-13 16:30:00\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Mise en forme de la date\n",
    "## ¨pit avoir toutes les années tout format de quatre charactères. Ex: ( 5 -> 005 -> 05 -> 2005)  , (16 -> 0016, 16 -> 2016)\n",
    "df_acc_usr['an']  = '20' + ('00' + df_acc_usr['an'].map(str) ).str[-2:]\n",
    "\n",
    "## Pour avoir tout les mois sous format de deux charactères. Ex: ( 1 -> 001 -> 01) , (13 -> 0013 -> 13)\n",
    "df_acc_usr['mois']  = ('00' + df_acc_usr['mois'].map(str)).str[-2:]\n",
    "\n",
    "## Pour avoir tout les jours sous format de deux charactères. Ex: ( 3 -> 003 -> 03) , (15 -> 0015 -> 15)\n",
    "df_acc_usr['jour']  = ('00' + df_acc_usr['jour'].map(str) ).str[-2:]\n",
    "\n",
    "## Pour avoir tout les jours sous format de quatre charactères. Ex: ( 3 -> 003 -> 003) , (1250 -> 001250 -> 1250) , (230 -> 00230 -> 0230)\n",
    "df_acc_usr['hrmn']  = ('00' + df_acc_usr['hrmn'].map(str) ).str[-4:]\n",
    "\n",
    "## Ajout de la colonne Date\n",
    "df_acc_usr['Date'] = pd.to_datetime(df_acc_usr['an'] + df_acc_usr['mois'] + df_acc_usr['jour'] + df_acc_usr['hrmn'] , format='%Y%m%d%H%M')\n",
    "print(df_acc_usr['Date'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcule des ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    49.0\n",
      "1    44.0\n",
      "2    50.0\n",
      "3    64.0\n",
      "4    57.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_acc_usr['age'] = ( np.int64(df_acc_usr['an']) - df_acc_usr['an_nais'] )\n",
    "print(df_acc_usr['age'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supression des colonnes non utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supression des colonnes inutiles\n",
    "df_acc_usr = df_acc_usr.drop(['an', 'mois', 'jour', 'hrmn', 'com', 'adr'\n",
    "                 , 'gps', 'lat', 'long', 'dep', 'an_nais', 'num_veh'\n",
    "                              , 'env1', 'place', 'trajet'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changement des types de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_usr = df_acc_usr.astype({\n",
    "    'lum': 'category', 'agg': 'category', 'int': 'category', \n",
    "    'atm': 'category', 'col': 'category', 'catr': 'category',\n",
    "    'circ': 'category', 'vosp': 'category', 'prof': 'category',\n",
    "    'plan': 'category', 'surf': 'category', 'infra': 'category', \n",
    "    'situ': 'category', 'catu': 'category', 'grav': 'category',\n",
    "    'sexe': 'category'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aperçu des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lum</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>catr</th>\n",
       "      <th>circ</th>\n",
       "      <th>vosp</th>\n",
       "      <th>prof</th>\n",
       "      <th>plan</th>\n",
       "      <th>surf</th>\n",
       "      <th>infra</th>\n",
       "      <th>situ</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2142195</td>\n",
       "      <td>2142195</td>\n",
       "      <td>2142195</td>\n",
       "      <td>2142046.0</td>\n",
       "      <td>2142152.0</td>\n",
       "      <td>2142193.0</td>\n",
       "      <td>2138626.0</td>\n",
       "      <td>2135842.0</td>\n",
       "      <td>2137752.0</td>\n",
       "      <td>2136789.0</td>\n",
       "      <td>2137788.0</td>\n",
       "      <td>2129595.0</td>\n",
       "      <td>2130588.0</td>\n",
       "      <td>2142195</td>\n",
       "      <td>2142195</td>\n",
       "      <td>2142195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1476913</td>\n",
       "      <td>1409485</td>\n",
       "      <td>1508764</td>\n",
       "      <td>1731553.0</td>\n",
       "      <td>646254.0</td>\n",
       "      <td>1020816.0</td>\n",
       "      <td>1348599.0</td>\n",
       "      <td>2004172.0</td>\n",
       "      <td>1630969.0</td>\n",
       "      <td>1653317.0</td>\n",
       "      <td>1673260.0</td>\n",
       "      <td>1888746.0</td>\n",
       "      <td>1837742.0</td>\n",
       "      <td>1594260</td>\n",
       "      <td>2084614</td>\n",
       "      <td>1439318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lum      agg      int        atm        col       catr       circ  \\\n",
       "count   2142195  2142195  2142195  2142046.0  2142152.0  2142193.0  2138626.0   \n",
       "unique        5        2       10        9.0        7.0        8.0        5.0   \n",
       "top           1        2        1        1.0        3.0        4.0        2.0   \n",
       "freq    1476913  1409485  1508764  1731553.0   646254.0  1020816.0  1348599.0   \n",
       "\n",
       "             vosp       prof       plan       surf      infra       situ  \\\n",
       "count   2135842.0  2137752.0  2136789.0  2137788.0  2129595.0  2130588.0   \n",
       "unique        4.0        5.0        5.0       10.0        8.0        6.0   \n",
       "top           0.0        1.0        1.0        1.0        0.0        1.0   \n",
       "freq    2004172.0  1630969.0  1653317.0  1673260.0  1888746.0  1837742.0   \n",
       "\n",
       "           catu     grav     sexe  \n",
       "count   2142195  2142195  2142195  \n",
       "unique        4        2        2  \n",
       "top           1        0        1  \n",
       "freq    1594260  2084614  1439318  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_usr.describe(percentiles=None, include='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>v1</th>\n",
       "      <th>nbv</th>\n",
       "      <th>pr</th>\n",
       "      <th>pr1</th>\n",
       "      <th>lartpc</th>\n",
       "      <th>larrout</th>\n",
       "      <th>secu</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.142195e+06</td>\n",
       "      <td>750230.000000</td>\n",
       "      <td>2.135950e+06</td>\n",
       "      <td>1.121537e+06</td>\n",
       "      <td>1.117644e+06</td>\n",
       "      <td>2.014575e+06</td>\n",
       "      <td>2.018811e+06</td>\n",
       "      <td>2.085658e+06</td>\n",
       "      <td>2.085834e+06</td>\n",
       "      <td>2.085733e+06</td>\n",
       "      <td>2.085777e+06</td>\n",
       "      <td>2.139777e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.010923e+11</td>\n",
       "      <td>0.079216</td>\n",
       "      <td>2.107546e+00</td>\n",
       "      <td>9.236276e+01</td>\n",
       "      <td>2.899833e+02</td>\n",
       "      <td>5.575486e+00</td>\n",
       "      <td>5.985202e+01</td>\n",
       "      <td>1.796288e+01</td>\n",
       "      <td>2.307082e-01</td>\n",
       "      <td>2.834946e-01</td>\n",
       "      <td>1.053665e-01</td>\n",
       "      <td>3.748199e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.081452e+08</td>\n",
       "      <td>0.608558</td>\n",
       "      <td>1.528709e+00</td>\n",
       "      <td>4.428746e+02</td>\n",
       "      <td>3.586551e+02</td>\n",
       "      <td>2.332773e+01</td>\n",
       "      <td>6.585246e+01</td>\n",
       "      <td>1.929059e+01</td>\n",
       "      <td>8.830024e-01</td>\n",
       "      <td>1.063983e+00</td>\n",
       "      <td>3.849168e-01</td>\n",
       "      <td>1.826791e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.005000e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.007001e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.011000e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.450000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.014001e+11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.018001e+11</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>9.929000e+03</td>\n",
       "      <td>9.540000e+03</td>\n",
       "      <td>9.600000e+02</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.090000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Num_Acc             v1           nbv            pr           pr1  \\\n",
       "count  2.142195e+06  750230.000000  2.135950e+06  1.121537e+06  1.117644e+06   \n",
       "mean   2.010923e+11       0.079216  2.107546e+00  9.236276e+01  2.899833e+02   \n",
       "std    4.081452e+08       0.608558  1.528709e+00  4.428746e+02  3.586551e+02   \n",
       "min    2.005000e+11       0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.007001e+11       0.000000  2.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    2.011000e+11       0.000000  2.000000e+00  7.000000e+00  1.450000e+02   \n",
       "75%    2.014001e+11       0.000000  2.000000e+00  3.000000e+01  5.000000e+02   \n",
       "max    2.018001e+11       9.000000  9.900000e+01  9.929000e+03  9.540000e+03   \n",
       "\n",
       "             lartpc       larrout          secu          locp          actp  \\\n",
       "count  2.014575e+06  2.018811e+06  2.085658e+06  2.085834e+06  2.085733e+06   \n",
       "mean   5.575486e+00  5.985202e+01  1.796288e+01  2.307082e-01  2.834946e-01   \n",
       "std    2.332773e+01  6.585246e+01  1.929059e+01  8.830024e-01  1.063983e+00   \n",
       "min    0.000000e+00 -8.100000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  1.100000e+01  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  6.000000e+01  1.100000e+01  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  8.000000e+01  2.100000e+01  0.000000e+00  0.000000e+00   \n",
       "max    9.600000e+02  9.990000e+02  9.300000e+01  8.000000e+00  9.000000e+00   \n",
       "\n",
       "              etatp           age  \n",
       "count  2.085777e+06  2.139777e+06  \n",
       "mean   1.053665e-01  3.748199e+01  \n",
       "std    3.849168e-01  1.826791e+01  \n",
       "min    0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  2.300000e+01  \n",
       "50%    0.000000e+00  3.400000e+01  \n",
       "75%    0.000000e+00  5.000000e+01  \n",
       "max    3.000000e+00  1.090000e+02  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc_usr.describe(percentiles=None, exclude=['category', 'datetime', 'object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taux de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_values = pd.DataFrame(df_acc_usr.isnull().sum())[0]\n",
    "df_missing_values = pd.DataFrame({'colonne':df_missing_values.index, 'nbr_manquant':df_missing_values.values})\n",
    "nbr_lignes = df_acc_usr['Num_Acc'].count()\n",
    "df_missing_values[\"%_missing\"] = ((df_missing_values['nbr_manquant'] / nbr_lignes )* 100 ).round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supression des colonnes avec trop de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_usr = df_acc_usr.drop(['v1', 'v2', 'pr', 'pr1', 'voie', 'larrout', 'lartpc'\n",
    "               , 'nbv', 'locp', 'secu', 'actp', 'etatp'] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Number of manager items must equal union of block items\n# manager items: 18, # tot_items: 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a8a062efe11a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# De l'imputation résulte un numpy_darray, il faudra le transformer en dataframe pour continuer les analyses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m imputed_df_acc_usr = pd.DataFrame(imputed_df_acc_usr, columns=['lum', 'agg', 'int', 'atm', 'col', \n\u001b[0m\u001b[0;32m     11\u001b[0m                                                                \u001b[1;34m'catr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'circ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vosp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'prof'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'plan'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'surf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                                                \u001b[1;34m'infra'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'situ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'catu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'grav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sexe'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1630\u001b[0m                 ]\n\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;31m# Populate known_consolidate, blknos, and blklocs lazily\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m    319\u001b[0m                 \u001b[1;34m\"Number of manager items must equal union of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;34mf\"block items\\n# manager items: {len(self.items)}, # \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Number of manager items must equal union of block items\n# manager items: 18, # tot_items: 19"
     ]
    }
   ],
   "source": [
    "# Remplacer les valeurs manquantes de l'age par la moyenne\n",
    "df_acc_usr['age'].fillna(df_acc_usr['age'].mean(), inplace=True)\n",
    "\n",
    "# Je n'ai pas pu remplacer les valeurs manquantes des attribtuts quali de la même façon à cause d'un bug panda https://github.com/pandas-dev/pandas/issues/35731\n",
    "# J'ai utilisé l'imputer de sklearner à la place\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "imputed_df_acc_usr = imp.fit_transform(df_acc_usr)\n",
    "\n",
    "# De l'imputation résulte un numpy_darray, il faudra le transformer en dataframe pour continuer les analyses\n",
    "imputed_df_acc_usr = pd.DataFrame(imputed_df_acc_usr, columns=['lum', 'agg', 'int', 'atm', 'col', \n",
    "                                                               'catr', 'circ', 'vosp','prof', 'plan', 'surf', \n",
    "                                                               'infra', 'situ', 'catu','grav', 'sexe', \n",
    "                                                               'Date', 'age'])\n",
    "\n",
    "# Verifier que toutes les valeurs manquantes ont été remplacées\n",
    "df_missing_values = pd.DataFrame(imputed_df_acc_usr.isnull().sum())[0]\n",
    "df_missing_values = pd.DataFrame({'colonne':df_missing_values.index, 'nbr_manquant':df_missing_values.values})\n",
    "nbr_lignes = df_acc_usr['Num_Acc'].count()\n",
    "df_missing_values[\"%_missing\"] = ((df_missing_values['nbr_manquant'] / nbr_lignes )* 100 ).round(decimals=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df_acc_usr.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des dataframe utilisés pour l'analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accidents par année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccidentDates = df_acc_usr['Date']\n",
    "AccidentByYear = AccidentDates.groupby([df_acc_usr['Date'].dt.year.rename('annee')]).agg({'count'})\n",
    "AccidentByYear.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Accidents par mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccidentByMonth = pd.DataFrame({'Date' :  df_acc_usr['Date']  , 'Accidents' : 1})\n",
    "AccidentByMonth['year_month'] = pd.to_datetime(((AccidentByMonth['Date'].dt.year).map(str) + (AccidentByMonth['Date'].dt.month).map(str)) , format='%Y%m')\n",
    "AccidentByMonth = AccidentByMonth.groupby('year_month' , as_index=False)['Accidents'].sum()\n",
    "\n",
    "AccidentByMonth['annee'] = AccidentByMonth['year_month'].dt.year\n",
    "AccidentByMonth['mois'] = AccidentByMonth['year_month'].dt.month_name()\n",
    "del AccidentByMonth['year_month']\n",
    "AccidentByMonth_pivoted = AccidentByMonth.pivot(index='mois', columns='annee', values='Accidents')\n",
    "AccidentByMonth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machin learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prédiction de la gravité de l'accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des colonnes à utiliser pour la prédiction\n",
    "feature_cols = list(df_acc_usr.columns) # Lister toutes les colonnes\n",
    "feature_cols.remove('Num_Acc') # Colonne non utilisée\n",
    "feature_cols.remove('Date') # Colonne non utilisée\n",
    "feature_cols.remove('grav') # Colonne non utilisée\n",
    "\n",
    "# DF des observations\n",
    "X = imputed_df_acc_usr[feature_cols] \n",
    "\n",
    "# DF cible\n",
    "y = df_acc_usr['grav'] \n",
    "\n",
    "# Découper le dataset en aprentissage et teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Création d'un objet arbre de décision, critère de division est l'entropy\n",
    "clf = DecisionTreeClassifier(max_depth=6, criterion = \"entropy\")\n",
    "# Aprentissage d'arbre de décision\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# Prédiction sur le dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('En utilisant les colonnes  \\n{}'.format(feature_cols))\n",
    "print(\"nous avont pu prédit le type d accident avec une accuracy de :\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
